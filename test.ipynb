{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00cc9653",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\15038\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a2d961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import json\n",
    "import re\n",
    "from config.config import THEME_COLOR\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "# Download NLTK resources if needed\n",
    "try:\n",
    "    nltk.download('punkt_tab')\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt_tab')\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "def render_resume_analysis():\n",
    "    \"\"\"Render the resume analysis component with adaptive UI.\"\"\"\n",
    "    if \"resume_data\" not in st.session_state or not st.session_state.resume_data:\n",
    "        st.warning(\"Please upload and analyze your resume first!\")\n",
    "        return\n",
    "    \n",
    "    resume_data = st.session_state.resume_data\n",
    "    \n",
    "    # Display header with animation\n",
    "    st.markdown(f\"\"\"\n",
    "    <style>\n",
    "    .resume-header {{\n",
    "        background: linear-gradient(90deg, {THEME_COLOR}10, {THEME_COLOR}30, {THEME_COLOR}10);\n",
    "        background-size: 200% 100%;\n",
    "        animation: gradient-animation 3s ease infinite;\n",
    "        padding: 15px;\n",
    "        border-radius: 10px;\n",
    "        text-align: center;\n",
    "        margin-bottom: 20px;\n",
    "    }}\n",
    "    @keyframes gradient-animation {{\n",
    "        0% {{background-position: 0% 50%}}\n",
    "        50% {{background-position: 100% 50%}}\n",
    "        100% {{background-position: 0% 50%}}\n",
    "    }}\n",
    "    .section-card {{\n",
    "        background-color: white;\n",
    "        border-radius: 10px;\n",
    "        padding: 15px;\n",
    "        box-shadow: 0 4px 6px rgba(0,0,0,0.05);\n",
    "        margin-bottom: 15px;\n",
    "    }}\n",
    "    .highlight-text {{\n",
    "        color: {THEME_COLOR};\n",
    "        font-weight: bold;\n",
    "    }}\n",
    "    .skill-tag {{\n",
    "        display: inline-block;\n",
    "        background-color: {THEME_COLOR}20;\n",
    "        color: {THEME_COLOR};\n",
    "        padding: 3px 10px;\n",
    "        border-radius: 15px;\n",
    "        margin: 5px 5px 5px 0px;\n",
    "        font-size: 0.9em;\n",
    "        transition: transform 0.2s;\n",
    "    }}\n",
    "    .skill-tag:hover {{\n",
    "        transform: scale(1.05);\n",
    "        background-color: {THEME_COLOR}30;\n",
    "    }}\n",
    "    .progress-container {{\n",
    "        width: 100%;\n",
    "        background-color: #e0e0e0;\n",
    "        border-radius: 5px;\n",
    "        margin: 5px 0;\n",
    "    }}\n",
    "    .progress-bar {{\n",
    "        height: 10px;\n",
    "        background-color: {THEME_COLOR};\n",
    "        border-radius: 5px;\n",
    "    }}\n",
    "    .ats-meter {{\n",
    "        width: 200px;\n",
    "        height: 100px;\n",
    "        position: relative;\n",
    "        margin: 20px auto;\n",
    "    }}\n",
    "    .ats-meter-gauge {{\n",
    "        width: 100%;\n",
    "        height: 100%;\n",
    "        position: relative;\n",
    "        border-radius: 100px 100px 0 0;\n",
    "        overflow: hidden;\n",
    "        background-color: #f3f3f3;\n",
    "    }}\n",
    "    .ats-meter-fill {{\n",
    "        position: absolute;\n",
    "        bottom: 0;\n",
    "        left: 0;\n",
    "        width: 100%;\n",
    "        border-radius: 0 0 100px 100px;\n",
    "        transition: height 1s ease-out;\n",
    "    }}\n",
    "    .ats-meter-text {{\n",
    "        position: absolute;\n",
    "        bottom: -5px;\n",
    "        left: 50%;\n",
    "        transform: translateX(-50%);\n",
    "        font-size: 24px;\n",
    "        font-weight: bold;\n",
    "    }}\n",
    "    .industry-match-card {{\n",
    "        border-left: 4px solid {THEME_COLOR};\n",
    "        padding: 10px 15px;\n",
    "        margin: 10px 0;\n",
    "        background-color: {THEME_COLOR}10;\n",
    "    }}\n",
    "    </style>\n",
    "    <div class=\"resume-header\">\n",
    "        <h2>‚ú® Resume Analysis Results ‚ú®</h2>\n",
    "    </div>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "    \n",
    "    # Try to identify the data format and structure\n",
    "    is_json = False\n",
    "    \n",
    "    if isinstance(resume_data, str):\n",
    "        try:\n",
    "            # Try to parse as JSON\n",
    "            parsed_data = json.loads(resume_data)\n",
    "            is_json = True\n",
    "            resume_data = parsed_data\n",
    "        except:\n",
    "            # Not JSON, keep as string\n",
    "            pass\n",
    "    \n",
    "    # Create tabs for navigation\n",
    "    tab_titles = [\"Overview\", \"Detailed Analysis\", \"ATS Optimization\"]\n",
    "    tabs = st.tabs([f\"üìã {tab_titles[0]}\", f\"üîç {tab_titles[1]}\", f\"üéØ {tab_titles[2]}\"])\n",
    "    \n",
    "    # Tab 1: Overview\n",
    "    with tabs[0]:\n",
    "        if isinstance(resume_data, dict):\n",
    "            # Handle dictionary data\n",
    "            for key, value in resume_data.items():\n",
    "                with st.expander(f\"üìÑ {key.replace('_', ' ').title()}\", expanded=True):\n",
    "                    render_section(key, value)\n",
    "        elif isinstance(resume_data, str):\n",
    "            # Handle string data - try to identify sections\n",
    "            st.markdown('<div class=\"section-card\">', unsafe_allow_html=True)\n",
    "            st.markdown(resume_data)\n",
    "            st.markdown('</div>', unsafe_allow_html=True)\n",
    "        else:\n",
    "            # Handle any other data type\n",
    "            st.json(resume_data)\n",
    "    \n",
    "    # Tab 2: Detailed Analysis - ENHANCED\n",
    "    with tabs[1]:\n",
    "        st.markdown(\"### Resume Analysis & Insights\")\n",
    "        \n",
    "        # Extract and analyze content\n",
    "        resume_text = \"\"\n",
    "        if isinstance(resume_data, str):\n",
    "            resume_text = resume_data\n",
    "        elif isinstance(resume_data, dict):\n",
    "            # Convert dict to text for analysis\n",
    "            resume_text = dict_to_text(resume_data)\n",
    "        \n",
    "        if resume_text:\n",
    "            # 1. Content statistics\n",
    "            st.markdown(\"#### üìä Content Statistics\")\n",
    "            words = len(re.findall(r'\\b\\w+\\b', resume_text))\n",
    "            sentences = len(re.findall(r'[.!?]+', resume_text)) + 1\n",
    "            paragraphs = len(re.findall(r'\\n\\s*\\n', resume_text)) + 1\n",
    "            \n",
    "            col1, col2, col3, col4 = st.columns(4)\n",
    "            col1.metric(\"Words\", words)\n",
    "            col2.metric(\"Sentences\", sentences)\n",
    "            col3.metric(\"Paragraphs\", paragraphs)\n",
    "            col4.metric(\"Readability\", \"Good\" if 10 <= words/sentences <= 20 else \"Review\")\n",
    "            \n",
    "            # 2. Action Verbs Analysis\n",
    "            st.markdown(\"#### üöÄ Action Verbs Analysis\")\n",
    "            \n",
    "            # Extract action verbs dynamically instead of hardcoding\n",
    "            action_verbs_found = extract_action_verbs(resume_text)\n",
    "            \n",
    "            # Display verb analysis\n",
    "            if action_verbs_found:\n",
    "                col1, col2 = st.columns([2, 1])\n",
    "                \n",
    "                with col1:\n",
    "                    st.markdown(\"##### Action Verbs Used\")\n",
    "                    verb_html = \"\"\n",
    "                    for verb in action_verbs_found[:20]:  # Limit to avoid overwhelming\n",
    "                        verb_html += f'<span class=\"skill-tag\">{verb}</span>'\n",
    "                    st.markdown(verb_html, unsafe_allow_html=True)\n",
    "                \n",
    "                with col2:\n",
    "                    st.markdown(\"##### Top Verbs\")\n",
    "                    verb_count = Counter(action_verbs_found)\n",
    "                    for verb, count in verb_count.most_common(5):\n",
    "                        st.markdown(f\"**{verb}**: {count} times\")\n",
    "                \n",
    "                # Action verb diversity score\n",
    "                unique_verbs = len(set(action_verbs_found))\n",
    "                diversity_score = min(unique_verbs * 5, 100)\n",
    "                st.markdown(f\"\"\"\n",
    "                <div class=\"progress-container\">\n",
    "                    <div class=\"progress-bar\" style=\"width: {diversity_score}%\"></div>\n",
    "                </div>\n",
    "                <p>Action Verb Diversity: {diversity_score}%</p>\n",
    "                \"\"\", unsafe_allow_html=True)\n",
    "                \n",
    "                # Provide feedback based on verb usage\n",
    "                if diversity_score < 40:\n",
    "                    st.info(\"Consider using more diverse action verbs to strengthen your resume.\")\n",
    "                elif diversity_score >= 80:\n",
    "                    st.success(\"Excellent use of diverse action verbs!\")\n",
    "            else:\n",
    "                st.warning(\"No action verbs detected. Consider adding strong action verbs to your resume.\")\n",
    "            \n",
    "            # 3. Skills Analysis\n",
    "            st.markdown(\"#### üí° Skills Analysis\")\n",
    "            \n",
    "            # Extract skills dynamically from text\n",
    "            all_skills = extract_skills_from_text(resume_text)\n",
    "            tech_skills = [skill for skill, category in all_skills if category == 'technical']\n",
    "            soft_skills = [skill for skill, category in all_skills if category == 'soft']\n",
    "            \n",
    "            col1, col2 = st.columns(2)\n",
    "            \n",
    "            with col1:\n",
    "                st.markdown(\"##### Technical Skills\")\n",
    "                if tech_skills:\n",
    "                    tech_html = \"\"\n",
    "                    for skill in tech_skills:\n",
    "                        tech_html += f'<span class=\"skill-tag\">{skill}</span>'\n",
    "                    st.markdown(tech_html, unsafe_allow_html=True)\n",
    "                else:\n",
    "                    st.info(\"No specific technical skills detected.\")\n",
    "            \n",
    "            with col2:\n",
    "                st.markdown(\"##### Soft Skills\")\n",
    "                if soft_skills:\n",
    "                    soft_html = \"\"\n",
    "                    for skill in soft_skills:\n",
    "                        soft_html += f'<span class=\"skill-tag\">{skill}</span>'\n",
    "                    st.markdown(soft_html, unsafe_allow_html=True)\n",
    "                else:\n",
    "                    st.info(\"No specific soft skills detected.\")\n",
    "            \n",
    "            # Skills balance analysis\n",
    "            if tech_skills or soft_skills:\n",
    "                tech_count = len(tech_skills)\n",
    "                soft_count = len(soft_skills)\n",
    "                total = tech_count + soft_count\n",
    "                \n",
    "                if total > 0:\n",
    "                    tech_percent = (tech_count / total) * 100\n",
    "                    soft_percent = (soft_count / total) * 100\n",
    "                    \n",
    "                    st.markdown(\"##### Skills Balance\")\n",
    "                    st.markdown(f\"\"\"\n",
    "                    <div class=\"progress-container\">\n",
    "                        <div class=\"progress-bar\" style=\"width: {tech_percent}%; background-color: {THEME_COLOR};\"></div>\n",
    "                        <div class=\"progress-bar\" style=\"width: {soft_percent}%; background-color: #6c757d; margin-left: 2px;\"></div>\n",
    "                    </div>\n",
    "                    <p>Technical: {tech_percent:.1f}% | Soft: {soft_percent:.1f}%</p>\n",
    "                    \"\"\", unsafe_allow_html=True)\n",
    "                    \n",
    "                    # Provide balance feedback\n",
    "                    if tech_percent > 80:\n",
    "                        st.info(\"Your resume is heavily technical. Consider highlighting more soft skills if relevant to your target roles.\")\n",
    "                    elif soft_percent > 80:\n",
    "                        st.info(\"Your resume emphasizes soft skills. Consider adding more technical skills if relevant to your target roles.\")\n",
    "                    else:\n",
    "                        st.success(\"Good balance between technical and soft skills!\")\n",
    "            \n",
    "            # 4. Experience Analysis\n",
    "            st.markdown(\"#### üëî Experience Analysis\")\n",
    "            \n",
    "            # Extract years of experience\n",
    "            experience_years, experience_details = extract_experience_details(resume_text)\n",
    "            \n",
    "            if experience_years:\n",
    "                st.metric(\"Estimated Experience\", f\"{experience_years} years\")\n",
    "                \n",
    "                # Experience level classification\n",
    "                if experience_years < 2:\n",
    "                    level = \"Entry Level\"\n",
    "                elif experience_years < 5:\n",
    "                    level = \"Mid Level\"\n",
    "                elif experience_years < 10:\n",
    "                    level = \"Senior Level\"\n",
    "                else:\n",
    "                    level = \"Executive Level\"\n",
    "                    \n",
    "                st.markdown(f\"Based on your experience, your profile appears to be **{level}**.\")\n",
    "                \n",
    "                # Show extracted experience details\n",
    "                if experience_details:\n",
    "                    st.markdown(\"##### Experience Timeline\")\n",
    "                    for period, details in experience_details.items():\n",
    "                        st.markdown(f\"**{period}**: {details}\")\n",
    "            else:\n",
    "                st.info(\"Could not determine years of experience. Ensure your resume includes clear work duration details.\")\n",
    "            \n",
    "            # 5. Education Analysis\n",
    "            st.markdown(\"#### üéì Education Analysis\")\n",
    "            education_details = extract_education_dynamic(resume_text)\n",
    "            \n",
    "            if education_details:\n",
    "                st.markdown(f\"**Highest Education**: {education_details.get('highest_degree', 'Not specified')}\")\n",
    "                if 'institutions' in education_details and education_details['institutions']:\n",
    "                    st.markdown(\"**Institutions:**\")\n",
    "                    for institution in education_details['institutions']:\n",
    "                        st.markdown(f\"- {institution}\")\n",
    "                if 'fields' in education_details and education_details['fields']:\n",
    "                    st.markdown(\"**Fields of Study:**\")\n",
    "                    for field in education_details['fields']:\n",
    "                        st.markdown(f\"- {field}\")\n",
    "            else:\n",
    "                st.info(\"Education details not clearly identified. Consider structuring your education section more clearly.\")\n",
    "            \n",
    "            # 6. Contact Information Analysis\n",
    "            st.markdown(\"#### üìû Contact Information\")\n",
    "            contact_info = extract_contact_info(resume_text)\n",
    "            \n",
    "            if contact_info:\n",
    "                for label, value in contact_info.items():\n",
    "                    st.markdown(f\"**{label}**: {value}\")\n",
    "                \n",
    "                # Check completeness\n",
    "                essential_contacts = ['Email', 'Phone', 'LinkedIn']\n",
    "                missing = [item for item in essential_contacts if item not in contact_info]\n",
    "                \n",
    "                if missing:\n",
    "                    st.warning(f\"Missing recommended contact details: {', '.join(missing)}\")\n",
    "                else:\n",
    "                    st.success(\"All essential contact information is present!\")\n",
    "            else:\n",
    "                st.warning(\"No contact information detected. Make sure to include your email and phone number.\")\n",
    "            \n",
    "            # 7. Resume Summary\n",
    "            st.markdown(\"#### üìù Resume Summary\")\n",
    "            summary = extract_summary(resume_text)\n",
    "            \n",
    "            if summary:\n",
    "                st.markdown(f\"**Summary**: {summary}\")\n",
    "            else:\n",
    "                st.info(\"No clear summary section detected. A concise professional summary can help highlight your value proposition.\")\n",
    "            \n",
    "    # Tab 3: ATS Optimization\n",
    "    with tabs[2]:\n",
    "        st.markdown(\"### üéØ ATS Optimization Analysis\")\n",
    "        \n",
    "        # Detect industry/field from resume\n",
    "        detected_industry = detect_industry(resume_text)\n",
    "        if detected_industry:\n",
    "            st.markdown(f\"\"\"\n",
    "            <div class=\"industry-match-card\">\n",
    "                <h4>Detected Field: {detected_industry['name']}</h4>\n",
    "                <p>Your resume appears to be targeting the <b>{detected_industry['name']}</b> field.</p>\n",
    "            </div>\n",
    "            \"\"\", unsafe_allow_html=True)\n",
    "            \n",
    "            # Create field selector for comparison\n",
    "            selected_industry = st.selectbox(\n",
    "                \"Compare with industry requirements:\", \n",
    "                [detected_industry['name']] + get_common_industries(exclude=detected_industry['name'])\n",
    "            )\n",
    "        else:\n",
    "            st.warning(\"Could not automatically detect your target field.\")\n",
    "            selected_industry = st.selectbox(\n",
    "                \"Select your target industry for analysis:\", \n",
    "                get_common_industries()\n",
    "            )\n",
    "            detected_industry = {\"name\": selected_industry}\n",
    "        \n",
    "        # Calculate ATS score based on resume content and selected industry\n",
    "        ats_score, ats_components = calculate_ats_score(resume_text, detected_industry['name'])\n",
    "        \n",
    "        # Display ATS score with a gauge\n",
    "        score_color = \"#28a745\" if ats_score >= 80 else \"#ffc107\" if ats_score >= 60 else \"#dc3545\"\n",
    "        st.markdown(f\"\"\"\n",
    "        <div class=\"ats-meter\">\n",
    "            <div class=\"ats-meter-gauge\">\n",
    "                <div class=\"ats-meter-fill\" style=\"height: {ats_score}%; background-color: {score_color};\"></div>\n",
    "            </div>\n",
    "            <div class=\"ats-meter-text\">{ats_score}%</div>\n",
    "        </div>\n",
    "        <h3 style=\"text-align: center;\">ATS Compatibility Score</h3>\n",
    "        \"\"\", unsafe_allow_html=True)\n",
    "        \n",
    "        # Display score breakdown\n",
    "        st.markdown(\"#### Score Breakdown\")\n",
    "        col1, col2 = st.columns(2)\n",
    "        \n",
    "        with col1:\n",
    "            for component, details in list(ats_components.items())[:len(ats_components)//2]:\n",
    "                st.markdown(f\"**{component}**: {details['score']}%\")\n",
    "                st.progress(details['score']/100)\n",
    "        \n",
    "        with col2:\n",
    "            for component, details in list(ats_components.items())[len(ats_components)//2:]:\n",
    "                st.markdown(f\"**{component}**: {details['score']}%\")\n",
    "                st.progress(details['score']/100)\n",
    "        \n",
    "        # Industry match analysis\n",
    "        st.markdown(\"#### Industry-Specific Analysis\")\n",
    "        industry_keywords = get_industry_keywords(detected_industry['name'])\n",
    "        \n",
    "        # Calculate percentage of industry keywords present\n",
    "        found_keywords = []\n",
    "        for keyword in industry_keywords:\n",
    "            if re.search(r'\\b' + re.escape(keyword) + r'\\b', resume_text.lower()):\n",
    "                found_keywords.append(keyword)\n",
    "        \n",
    "        keyword_match = len(found_keywords) / len(industry_keywords) * 100 if industry_keywords else 0\n",
    "        \n",
    "        st.markdown(f\"\"\"\n",
    "        <div class=\"progress-container\">\n",
    "            <div class=\"progress-bar\" style=\"width: {keyword_match}%;\"></div>\n",
    "        </div>\n",
    "        <p>Industry Keyword Match: {keyword_match:.1f}%</p>\n",
    "        \"\"\", unsafe_allow_html=True)\n",
    "        \n",
    "        # Show keywords found and missing\n",
    "        col1, col2 = st.columns(2)\n",
    "        \n",
    "        with col1:\n",
    "            st.markdown(\"##### ‚úÖ Keywords Found\")\n",
    "            if found_keywords:\n",
    "                keywords_html = \"\"\n",
    "                for keyword in found_keywords:\n",
    "                    keywords_html += f'<span class=\"skill-tag\">{keyword}</span>'\n",
    "                st.markdown(keywords_html, unsafe_allow_html=True)\n",
    "            else:\n",
    "                st.info(\"No industry-specific keywords found.\")\n",
    "        \n",
    "        with col2:\n",
    "            st.markdown(\"##### ‚ùå Missing Keywords\")\n",
    "            missing_keywords = [k for k in industry_keywords if k not in found_keywords]\n",
    "            if missing_keywords:\n",
    "                keywords_html = \"\"\n",
    "                for keyword in missing_keywords[:10]:  # Limit to top 10\n",
    "                    keywords_html += f'<span class=\"skill-tag\">{keyword}</span>'\n",
    "                st.markdown(keywords_html, unsafe_allow_html=True)\n",
    "                if len(missing_keywords) > 10:\n",
    "                    st.info(f\"... and {len(missing_keywords) - 10} more\")\n",
    "            else:\n",
    "                st.success(\"Great job! Your resume includes all relevant industry keywords.\")\n",
    "        \n",
    "        # Recommendations for improvement\n",
    "        st.markdown(\"#### Recommendations for Improvement\")\n",
    "        recommendations = generate_ats_recommendations(resume_text, ats_components, detected_industry['name'])\n",
    "        \n",
    "        for category, rec_list in recommendations.items():\n",
    "            with st.expander(f\"üìù {category}\", expanded=True):\n",
    "                for recommendation in rec_list:\n",
    "                    st.markdown(f\"- {recommendation}\")\n",
    "\n",
    "        # ATS Format Analysis\n",
    "        st.markdown(\"#### üìÑ ATS Format Analysis\")\n",
    "        format_issues = analyze_resume_format(resume_text)\n",
    "        \n",
    "        if not format_issues:\n",
    "            st.success(\"Your resume format appears to be ATS-friendly!\")\n",
    "        else:\n",
    "            st.warning(\"Detected format issues that might affect ATS compatibility:\")\n",
    "            for issue in format_issues:\n",
    "                st.markdown(f\"- {issue}\")\n",
    "        \n",
    "        # File format recommendation\n",
    "        st.info(\"**Pro Tip**: Save your resume as a .docx or .pdf file with simple formatting for best ATS compatibility.\")\n",
    "        \n",
    "        # ATS Keyword Position Analysis\n",
    "        st.markdown(\"#### üìä Keyword Position Analysis\")\n",
    "        position_analysis = analyze_keyword_positions(resume_text, found_keywords)\n",
    "        \n",
    "        if position_analysis.get('score', 0) >= 70:\n",
    "            st.success(f\"Keyword positioning score: {position_analysis.get('score')}% - Good placement!\")\n",
    "        else:\n",
    "            st.warning(f\"Keyword positioning score: {position_analysis.get('score')}% - Could be improved\")\n",
    "            \n",
    "        st.markdown(position_analysis.get('suggestion', ''))\n",
    "    \n",
    "    # Add action buttons at the bottom\n",
    "    col1, col2 = st.columns(2)\n",
    "    with col1:\n",
    "        st.download_button(\n",
    "            label=\"üì• Download Analysis\",\n",
    "            data=json.dumps(resume_data, indent=2) if isinstance(resume_data, dict) else str(resume_data),\n",
    "            file_name=\"resume_analysis.txt\",\n",
    "            mime=\"text/plain\"\n",
    "        )\n",
    "    \n",
    "    with col2:\n",
    "        if st.button(\"üîÑ Regenerate Analysis\", type=\"primary\"):\n",
    "            if \"resume_path\" in st.session_state:\n",
    "                st.session_state.pop(\"resume_data\", None)\n",
    "                st.rerun()\n",
    "\n",
    "def render_section(key, value):\n",
    "    \"\"\"Dynamically render a section based on its content.\"\"\"\n",
    "    if isinstance(value, dict):\n",
    "        # Handle dictionary values\n",
    "        for k, v in value.items():\n",
    "            st.markdown(f\"**{k.replace('_', ' ').title()}**: {v}\")\n",
    "    \n",
    "    elif isinstance(value, list):\n",
    "        # Handle list values\n",
    "        if key.lower() in [\"skills\", \"technologies\", \"competencies\"]:\n",
    "            # Render as skill tags\n",
    "            skills_html = \"\"\n",
    "            for item in value:\n",
    "                if isinstance(item, str):\n",
    "                    skills_html += f'<span class=\"skill-tag\">{item}</span>'\n",
    "                else:\n",
    "                    st.write(item)\n",
    "            if skills_html:\n",
    "                st.markdown(skills_html, unsafe_allow_html=True)\n",
    "        \n",
    "        elif key.lower() in [\"experience\", \"work\", \"employment\", \"jobs\"]:\n",
    "            # Render as job experiences\n",
    "            for idx, item in enumerate(value):\n",
    "                if isinstance(item, dict):\n",
    "                    company = item.get(\"company\", item.get(\"organization\", \"Company\"))\n",
    "                    title = item.get(\"title\", item.get(\"position\", \"Role\"))\n",
    "                    with st.expander(f\"{title} at {company}\", expanded=idx==0):\n",
    "                        for k, v in item.items():\n",
    "                            if k not in [\"company\", \"organization\", \"title\", \"position\"]:\n",
    "                                st.markdown(f\"**{k.replace('_', ' ').title()}**: {v}\")\n",
    "                else:\n",
    "                    st.write(item)\n",
    "        \n",
    "        elif key.lower() in [\"education\", \"qualifications\", \"academic\"]:\n",
    "            # Render as education\n",
    "            for item in value:\n",
    "                if isinstance(item, dict):\n",
    "                    degree = item.get(\"degree\", item.get(\"qualification\", \"Degree\"))\n",
    "                    institution = item.get(\"institution\", item.get(\"school\", \"Institution\"))\n",
    "                    st.markdown(f\"**{degree}** - {institution}\")\n",
    "                    \n",
    "                    for k, v in item.items():\n",
    "                        if k not in [\"degree\", \"qualification\", \"institution\", \"school\"]:\n",
    "                            st.markdown(f\"*{k.replace('_', ' ').title()}*: {v}\")\n",
    "                    st.divider()\n",
    "                else:\n",
    "                    st.write(item)\n",
    "        \n",
    "        else:\n",
    "            # Generic list rendering\n",
    "            for item in value:\n",
    "                st.write(item)\n",
    "                st.divider()\n",
    "    \n",
    "    else:\n",
    "        # Handle string/number/other values\n",
    "        st.write(value)\n",
    "\n",
    "# Helper functions for detailed analysis\n",
    "def dict_to_text(data_dict):\n",
    "    \"\"\"Convert a dictionary to plain text for analysis.\"\"\"\n",
    "    text = \"\"\n",
    "    for key, value in data_dict.items():\n",
    "        text += f\"{key.replace('_', ' ').title()}:\\n\"\n",
    "        \n",
    "        if isinstance(value, dict):\n",
    "            for k, v in value.items():\n",
    "                text += f\"  {k.replace('_', ' ').title()}: {v}\\n\"\n",
    "        \n",
    "        elif isinstance(value, list):\n",
    "            for item in value:\n",
    "                if isinstance(item, dict):\n",
    "                    for k, v in item.items():\n",
    "                        text += f\"  {k.replace('_', ' ').title()}: {v}\\n\"\n",
    "                    text += \"\\n\"\n",
    "                else:\n",
    "                    text += f\"  - {item}\\n\"\n",
    "        \n",
    "        else:\n",
    "            text += f\"  {value}\\n\"\n",
    "        \n",
    "        text += \"\\n\"\n",
    "    \n",
    "    return text\n",
    "\n",
    "def extract_action_verbs(text):\n",
    "    \"\"\"Extract action verbs from text using NLP.\"\"\"\n",
    "    # Tokenize text\n",
    "    sentences = nltk.sent_tokenize(text.lower())\n",
    "    words = []\n",
    "    for sentence in sentences:\n",
    "        words.extend(nltk.word_tokenize(sentence))\n",
    "    \n",
    "    # Remove stopwords and non-alpha\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word.isalpha() and word not in stop_words]\n",
    "    \n",
    "    # Common action verb endings\n",
    "    action_verb_endings = ['ed', 'ing', 'ize', 'ate', 'en', 'fy', 'ish', 'uce']\n",
    "    \n",
    "    # Check for common action verbs in resume context\n",
    "    common_resume_verbs = [\n",
    "        'manage', 'lead', 'develop', 'create', 'implement', 'analyze', \n",
    "        'design', 'coordinate', 'establish', 'generate', 'launch', 'perform',\n",
    "        'deliver', 'build', 'resolve', 'transform', 'improve', 'increase',\n",
    "        'decrease', 'reduce', 'streamline', 'optimize', 'spearhead', 'pioneer'\n",
    "    ]\n",
    "    \n",
    "    # Extract verbs\n",
    "    action_verbs = []\n",
    "    for word in words:\n",
    "        # Check if it's a common resume verb\n",
    "        if word in common_resume_verbs or any(word.endswith(ending) for ending in action_verb_endings):\n",
    "            action_verbs.append(word)\n",
    "    \n",
    "    return action_verbs\n",
    "\n",
    "def extract_skills_from_text(text):\n",
    "    \"\"\"Extract skills from text using NLP approach.\"\"\"\n",
    "    # Tokenize and normalize text\n",
    "    text = text.lower()\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    \n",
    "    # Extract n-grams that might represent skills\n",
    "    all_phrases = []\n",
    "    for sentence in sentences:\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        \n",
    "        # Unigrams\n",
    "        all_phrases.extend(words)\n",
    "        \n",
    "        # Bigrams and trigrams\n",
    "        for n in range(2, 4):\n",
    "            for i in range(len(words) - n + 1):\n",
    "                all_phrases.append(' '.join(words[i:i+n]))\n",
    "    \n",
    "    # Filter out common non-skill words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Dictionary of skill domains and their relevant keywords\n",
    "    skill_domains = {\n",
    "        'technical': [\n",
    "            # Programming and Development\n",
    "            'python', 'java', 'javascript', 'html', 'css', 'sql', 'c++', 'c#', 'php', 'ruby',\n",
    "            'react', 'angular', 'vue', 'node', 'django', 'flask', 'spring', 'express',\n",
    "            'git', 'docker', 'kubernetes', 'aws', 'azure', 'gcp', 'cloud',\n",
    "            'restful api', 'graphql', 'database', 'algorithm', 'data structure',\n",
    "            \n",
    "            # Data Science & Analytics\n",
    "            'data analysis', 'machine learning', 'ai', 'artificial intelligence', 'neural network',\n",
    "            'deep learning', 'nlp', 'natural language', 'tensorflow', 'pytorch', 'scikit',\n",
    "            'data visualization', 'tableau', 'power bi', 'statistics', 'r programming',\n",
    "            \n",
    "            # Design\n",
    "            'ui design', 'ux design', 'user interface', 'user experience', 'wireframing',\n",
    "            'photoshop', 'illustrator', 'figma', 'sketch', 'indesign', 'typography',\n",
    "            \n",
    "            # Marketing & Business\n",
    "            'seo', 'sem', 'google analytics', 'social media', 'content marketing',\n",
    "            'email marketing', 'crm', 'salesforce', 'hubspot', 'market research',\n",
    "            \n",
    "            # Other Technical\n",
    "            'excel', 'word', 'powerpoint', 'office suite', 'project management',\n",
    "            'jira', 'trello', 'agile', 'scrum', 'kanban', 'waterfall',\n",
    "            'linux', 'unix', 'windows', 'macos', 'ios', 'android'\n",
    "        ],\n",
    "        'soft': [\n",
    "            'communication', 'teamwork', 'leadership', 'problem solving', 'critical thinking',\n",
    "            'time management', 'organization', 'adaptability', 'flexibility', 'creativity',\n",
    "            'emotional intelligence', 'conflict resolution', 'negotiation', 'persuasion',\n",
    "            'presentation', 'public speaking', 'customer service', 'client relations',\n",
    "            'mentoring', 'coaching', 'training', 'strategic thinking', 'analytical',\n",
    "            'research', 'writing', 'editing', 'attention to detail', 'multitasking',\n",
    "            'prioritization', 'resilience', 'stress management', 'work ethic',\n",
    "            'collaboration', 'interpersonal', 'networking', 'self-motivation'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Look for skill markers\n",
    "    skill_markers = [\n",
    "        'experience with', 'proficient in', 'skilled in', 'knowledge of', 'expertise in',\n",
    "        'familiar with', 'background in', 'trained in', 'certified in', 'specializing in',\n",
    "        'skills:', 'skill', 'proficiency', 'competency'\n",
    "    ]\n",
    "    \n",
    "    # Detect skills from the resume text\n",
    "    detected_skills = []\n",
    "    \n",
    "    # Detect skills based on predefined domains\n",
    "    for domain, keywords in skill_domains.items():\n",
    "        for keyword in keywords:\n",
    "            if re.search(r'\\b' + re.escape(keyword) + r'\\b', text):\n",
    "                detected_skills.append((keyword, domain))\n",
    "    \n",
    "    # Detect additional skills based on skill markers\n",
    "    for marker in skill_markers:\n",
    "        marker_pattern = re.escape(marker) + r'\\s+([\\w\\s,]+)(?:\\.|,|\\n)'\n",
    "        matches = re.finditer(marker_pattern, text)\n",
    "        for match in matches:\n",
    "            skill_text = match.group(1).strip()\n",
    "            skill_items = re.split(r',|\\s+and\\s+|\\s*[&‚Ä¢]\\s*', skill_text)\n",
    "            \n",
    "            for item in skill_items:\n",
    "                item = item.strip().lower()\n",
    "                if item and item not in stop_words and len(item) > 2:\n",
    "                    # Determine if technical or soft skill\n",
    "                    domain = 'technical'  # Default assumption\n",
    "                    if any(soft in item for soft in ['communication', 'leadership', 'teamwork']):\n",
    "                        domain = 'soft'\n",
    "                    \n",
    "                    if (item, domain) not in detected_skills:\n",
    "                        detected_skills.append((item, domain))\n",
    "    \n",
    "    return detected_skills\n",
    "\n",
    "def extract_experience_details(text):\n",
    "    \"\"\"Extract detailed experience information from resume text.\"\"\"\n",
    "    # Look for patterns like \"X years of experience\" or \"X+ years\"\n",
    "    year_patterns = [\n",
    "        r'(\\d+)(?:\\+)?\\s*(?:years|yrs)(?:\\s*of)?\\s*experience',\n",
    "        r'experience\\s*(?:of)?\\s*(\\d+)(?:\\+)?\\s*(?:years|yrs)',\n",
    "        r'(?:worked|working)\\s*(?:for)?\\s*(\\d+)(?:\\+)?\\s*(?:years|yrs)',\n",
    "    ]\n",
    "    \n",
    "    years = []\n",
    "    for pattern in year_patterns:\n",
    "        matches = re.findall(pattern, text.lower())\n",
    "        years.extend([int(y) for y in matches if y.isdigit()])\n",
    "    \n",
    "    total_years = max(years) if years else 0\n",
    "    \n",
    "    # Extract employment dates and details\n",
    "    date_ranges = re.findall(r'(20\\d{2}|19\\d{2})\\s*(?:-|to|‚Äì|‚Äî)\\s*(20\\d{2}|19\\d{2}|present|current|now)', text.lower())\n",
    "    \n",
    "    current_year = 2025  # Update as needed\n",
    "    experience_details = {}\n",
    "    \n",
    "    for start, end in date_ranges:\n",
    "        if start.isdigit():\n",
    "            end_year = current_year if end in ['present', 'current', 'now'] else int(end) if end.isdigit() else current_year\n",
    "            start_year = int(start)\n",
    "            duration = end_year - start_year\n",
    "            \n",
    "            # Extract context around the date to identify the role\n",
    "            context_pattern = r'([^\\.]*?' + re.escape(start) + r'[^\\.]*?' + re.escape(end) + r'[^\\.]*?\\.)'\n",
    "            context_matches = re.findall(context_pattern, text, re.IGNORECASE)\n",
    "            \n",
    "            context = context_matches[0] if context_matches else f\"Experience from {start} to {end}\"\n",
    "            experience_details[f\"{start}-{end}\"] = context\n",
    "            \n",
    "            # Update total years if not already detected from explicit statements\n",
    "            if not years:\n",
    "                years.append(duration)\n",
    "    \n",
    "    # Calculate total years if we have dates but no explicit statements\n",
    "    if not total_years and years:\n",
    "        total_years = sum(years)\n",
    "    \n",
    "    return total_years, experience_details\n",
    "\n",
    "def extract_education_dynamic(text):\n",
    "    \"\"\"Extract education details dynamically from resume text.\"\"\"\n",
    "    # Define education-related keywords and patterns\n",
    "    education_keywords = ['education', 'degree', 'university', 'college', 'school', 'academic', 'bachelor', 'master', 'phd', 'doctorate', 'diploma']\n",
    "    degree_patterns = [\n",
    "        r'(bachelor|master|phd|doctorate|b\\.?s\\.?|m\\.?s\\.?|b\\.?a\\.?|m\\.?a\\.?|m\\.?b\\.?a\\.?|ph\\.?d\\.?)',\n",
    "        r'(bachelor of|master of|doctor of)'\n",
    "    ]\n",
    "    \n",
    "    # Extract education section\n",
    "    education_section = \"\"\n",
    "    for keyword in education_keywords:\n",
    "        pattern = r'(?:' + re.escape(keyword) + r')(.+?)(?:experience|skills|work history|employment|references|projects|publications|certification|additional)'\n",
    "        matches = re.findall(pattern, text.lower(), re.DOTALL | re.IGNORECASE)\n",
    "        if matches:\n",
    "            education_section += ' ' + matches[0]\n",
    "    \n",
    "    if not education_section:\n",
    "        # Fallback: try to find any sentences containing degree-related words\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        for sentence in sentences:\n",
    "            if any(re.search(degree_pattern, sentence.lower()) for degree_pattern in degree_patterns):\n",
    "                education_section += ' ' + sentence\n",
    "    \n",
    "    if not education_section:\n",
    "        return None\n",
    "    \n",
    "    # Extract degree level\n",
    "    highest_degree = \"Not Specified\"\n",
    "    degree_levels = {\n",
    "        \"Doctorate\": [\"phd\", \"doctorate\", \"doctor of\", \"ph.d\"],\n",
    "        \"Master's\": [\"master\", \"m.s.\", \"m.a.\", \"mba\", \"master of\"],\n",
    "        \"Bachelor's\": [\"bachelor\", \"b.s.\", \"b.a.\", \"bachelor of\"],\n",
    "        \"Associate's\": [\"associate\", \"a.s.\", \"a.a.\"],\n",
    "        \"High School\": [\"high school\", \"diploma\", \"secondary\"]\n",
    "    }\n",
    "    \n",
    "    for level, keywords in degree_levels.items():\n",
    "        if any(re.search(r'\\b' + re.escape(kw) + r'\\b', education_section.lower()) for kw in keywords):\n",
    "            highest_degree = level\n",
    "            break\n",
    "    \n",
    "    # Extract institution names\n",
    "    institutions = []\n",
    "    common_institutions = [\"university\", \"college\", \"institute\", \"school\"]\n",
    "    for word in common_institutions:\n",
    "        pattern = r'(\\b\\w+\\s+' + re.escape(word) + r'\\b|\\b' + re.escape(word) + r' of \\w+(\\s+\\w+)?)'\n",
    "        matches = re.findall(pattern, education_section, re.IGNORECASE)\n",
    "        institutions.extend([m[0] for m in matches if m[0]])\n",
    "    \n",
    "    # Extract fields of study\n",
    "    fields = []\n",
    "    common_fields = [\"computer science\", \"engineering\", \"business\", \"administration\", \"finance\", \"economics\", \n",
    "                      \"mathematics\", \"psychology\", \"biology\", \"chemistry\", \"physics\", \"literature\", \"history\",\n",
    "                      \"communication\", \"marketing\", \"management\", \"accounting\", \"medicine\", \"law\"]\n",
    "    \n",
    "    for field in common_fields:\n",
    "        if re.search(r'\\b' + re.escape(field) + r'\\b', education_section.lower()):\n",
    "            fields.append(field)\n",
    "    \n",
    "    # Clean and deduplicate\n",
    "    institutions = list(set([i.strip().title() for i in institutions]))\n",
    "    fields = list(set([f.strip().title() for f in fields]))\n",
    "    \n",
    "    return {\n",
    "        \"highest_degree\": highest_degree,\n",
    "        \"institutions\": institutions,\n",
    "        \"fields\": fields\n",
    "    }\n",
    "\n",
    "def extract_contact_info(text):\n",
    "    \"\"\"Extract contact information from resume text.\"\"\"\n",
    "    contact_info = {}\n",
    "    \n",
    "    # Email\n",
    "    email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "    emails = re.findall(email_pattern, text)\n",
    "    if emails:\n",
    "        contact_info['Email'] = emails[0]\n",
    "    \n",
    "    # Phone\n",
    "    phone_pattern = r'\\b(?:\\+\\d{1,3}[-\\s]?)?\\(?\\d{3}\\)?[-\\s]?\\d{3}[-\\s]?\\d{4}\\b'\n",
    "    phones = re.findall(phone_pattern, text)\n",
    "    if phones:\n",
    "        contact_info['Phone'] = phones[0]\n",
    "    \n",
    "    # LinkedIn\n",
    "    linkedin_pattern = r'(?:linkedin\\.com/in/|linkedin:)([A-Za-z0-9_-]+)'\n",
    "    linkedin = re.findall(linkedin_pattern, text.lower())\n",
    "    if linkedin:\n",
    "        contact_info['LinkedIn'] = f\"linkedin.com/in/{linkedin[0]}\"\n",
    "    \n",
    "    # Website/Portfolio\n",
    "    website_pattern = r'(?:https?://)?(?:www\\.)?([A-Za-z0-9][-A-Za-z0-9]*\\.)+[A-Za-z]{2,}'\n",
    "    websites = re.findall(website_pattern, text)\n",
    "    if websites:\n",
    "        # Filter out common domains like gmail, linkedin, etc.\n",
    "        filtered_sites = [site for site in websites if not any(domain in site.lower() for domain in ['gmail', 'yahoo', 'hotmail', 'linkedin', 'facebook', 'twitter'])]\n",
    "        if filtered_sites:\n",
    "            contact_info['Website'] = filtered_sites[0]\n",
    "    \n",
    "    # Location\n",
    "    location_patterns = [\n",
    "        r'(?:location|address|city):\\s*([^,\\n]+(?:,\\s*[A-Z]{2})?)',\n",
    "        r'\\b([A-Za-z\\s]+,\\s*[A-Z]{2})\\b'\n",
    "    ]\n",
    "    \n",
    "    for pattern in location_patterns:\n",
    "        locations = re.findall(pattern, text)\n",
    "        if locations:\n",
    "            contact_info['Location'] = locations[0].strip()\n",
    "            break\n",
    "    \n",
    "    return contact_info\n",
    "\n",
    "def extract_summary(text):\n",
    "    \"\"\"Extract summary or professional statement from resume.\"\"\"\n",
    "    summary_patterns = [\n",
    "        r'(?:summary|profile|objective|about me|professional summary|professional profile)(?:[:\\s]*)([^\\.]+(?:\\.[^\\.]+){0,3})',\n",
    "        r'^([^\\.]+(?:\\.[^\\.]+){0,3})'\n",
    "    ]\n",
    "    \n",
    "    for pattern in summary_patterns:\n",
    "        summary = re.search(pattern, text, re.IGNORECASE | re.DOTALL)\n",
    "        if summary:\n",
    "            # Clean the summary\n",
    "            clean_summary = re.sub(r'\\s+', ' ', summary.group(1).strip())\n",
    "            return clean_summary\n",
    "    \n",
    "    return None\n",
    "\n",
    "def detect_industry(text):\n",
    "    \"\"\"Detect the most likely industry/field from resume text.\"\"\"\n",
    "    # Define industry keywords\n",
    "    industries = {\n",
    "        \"Software Development\": [\"software\", \"developer\", \"programming\", \"coder\", \"engineer\", \"java\", \"python\", \"javascript\", \"web developer\"],\n",
    "        \"Data Science\": [\"data science\", \"machine learning\", \"ai\", \"artificial intelligence\", \"data mining\", \"big data\", \"statistical\", \"data analysis\"],\n",
    "        \"Finance\": [\"finance\", \"accounting\", \"financial\", \"analyst\", \"investment\", \"banking\", \"budget\", \"cash flow\", \"audit\"],\n",
    "        \"Marketing\": [\"marketing\", \"seo\", \"social media\", \"brand\", \"content\", \"campaign\", \"digital marketing\", \"market research\"],\n",
    "        \"Healthcare\": [\"healthcare\", \"medical\", \"clinical\", \"nurse\", \"doctor\", \"patient\", \"hospital\", \"pharma\", \"health\"],\n",
    "        \"Education\": [\"education\", \"teacher\", \"professor\", \"academic\", \"curriculum\", \"teaching\", \"instructor\", \"school\", \"university\"],\n",
    "        \"Design\": [\"design\", \"designer\", \"creative\", \"ui\", \"ux\", \"graphic\", \"visual\", \"artwork\", \"illustrator\", \"photoshop\"],\n",
    "        \"Engineering\": [\"engineering\", \"mechanical\", \"electrical\", \"civil\", \"architect\", \"structural\", \"construction\"],\n",
    "        \"Project Management\": [\"project manager\", \"project management\", \"agile\", \"scrum\", \"pmp\", \"program\", \"delivery\", \"sprint\"],\n",
    "        \"Human Resources\": [\"hr\", \"human resources\", \"recruitment\", \"talent\", \"hiring\", \"onboarding\", \"benefits\", \"compensation\"]\n",
    "    }\n",
    "    \n",
    "    # Count keyword matches for each industry\n",
    "    industry_scores = {}\n",
    "    text = text.lower()\n",
    "    \n",
    "    for industry, keywords in industries.items():\n",
    "        score = 0\n",
    "        for keyword in keywords:\n",
    "            matches = re.findall(r'\\b' + re.escape(keyword) + r'\\b', text)\n",
    "            score += len(matches)\n",
    "        industry_scores[industry] = score\n",
    "    \n",
    "    # Find the industry with the highest score\n",
    "    if industry_scores:\n",
    "        top_industry = max(industry_scores.items(), key=lambda x: x[1])\n",
    "        if top_industry[1] > 0:\n",
    "            return {\"name\": top_industry[0], \"score\": top_industry[1]}\n",
    "    \n",
    "    return None\n",
    "\n",
    "def get_common_industries(exclude=None):\n",
    "    \"\"\"Get a list of common industries for the dropdown.\"\"\"\n",
    "    industries = [\n",
    "        \"Software Development\",\n",
    "        \"Data Science\",\n",
    "        \"Finance\",\n",
    "        \"Marketing\",\n",
    "        \"Healthcare\",\n",
    "        \"Education\",\n",
    "        \"Design\",\n",
    "        \"Engineering\",\n",
    "        \"Project Management\",\n",
    "        \"Human Resources\",\n",
    "        \"Sales\",\n",
    "        \"Customer Service\",\n",
    "        \"Consulting\",\n",
    "        \"Operations\",\n",
    "        \"Manufacturing\",\n",
    "        \"Legal\",\n",
    "        \"Content Writing\",\n",
    "        \"Administrative\",\n",
    "        \"Research\"\n",
    "    ]\n",
    "    \n",
    "    if exclude:\n",
    "        industries = [i for i in industries if i != exclude]\n",
    "    \n",
    "    return industries\n",
    "\n",
    "def get_industry_keywords(industry):\n",
    "    \"\"\"Get common keywords for a specific industry.\"\"\"\n",
    "    keywords_by_industry = {\n",
    "        \"Software Development\": [\n",
    "            \"software development\", \"programming\", \"coding\", \"java\", \"python\", \"javascript\", \n",
    "            \"full stack\", \"backend\", \"frontend\", \"web development\", \"mobile development\",\n",
    "            \"api\", \"git\", \"agile\", \"scrum\", \"devops\", \"testing\", \"debugging\", \"software engineer\"\n",
    "        ],\n",
    "        \"Data Science\": [\n",
    "            \"data science\", \"machine learning\", \"ai\", \"artificial intelligence\", \"data mining\",\n",
    "            \"big data\", \"statistical analysis\", \"data visualization\", \"predictive modeling\",\n",
    "            \"data cleaning\", \"python\", \"r\", \"sql\", \"tableau\", \"tensorflow\", \"pytorch\", \"analytics\"\n",
    "        ],\n",
    "        \"Finance\": [\n",
    "            \"financial analysis\", \"accounting\", \"budgeting\", \"forecasting\", \"investment\",\n",
    "            \"financial planning\", \"portfolio management\", \"risk assessment\", \"financial reporting\",\n",
    "            \"banking\", \"taxation\", \"audit\", \"compliance\", \"cpa\", \"financial statements\"\n",
    "        ],\n",
    "        \"Marketing\": [\n",
    "            \"marketing strategy\", \"digital marketing\", \"social media\", \"content marketing\",\n",
    "            \"seo\", \"sem\", \"analytics\", \"brand management\", \"market research\", \"campaign management\",\n",
    "            \"email marketing\", \"customer acquisition\", \"marketing automation\", \"conversion rate\"\n",
    "        ],\n",
    "        \"Healthcare\": [\n",
    "            \"patient care\", \"clinical\", \"medical\", \"healthcare\", \"diagnosis\", \"treatment\",\n",
    "            \"medical records\", \"hipaa\", \"patient satisfaction\", \"healthcare management\",\n",
    "            \"medical billing\", \"electronic health records\", \"hospital\", \"nursing\", \"pharmacy\"\n",
    "        ],\n",
    "        \"Education\": [\n",
    "            \"curriculum development\", \"instruction\", \"teaching\", \"assessment\", \"education\",\n",
    "            \"learning management\", \"student engagement\", \"classroom management\", \"pedagogy\",\n",
    "            \"educational technology\", \"student progress\", \"lesson planning\", \"academic advising\"\n",
    "        ],\n",
    "        \"Design\": [\n",
    "            \"design\", \"visual design\", \"ui design\", \"ux design\", \"graphic design\", \"user interface\",\n",
    "            \"user experience\", \"wireframing\", \"prototyping\", \"typography\", \"illustration\",\n",
    "            \"adobe creative suite\", \"photoshop\", \"illustrator\", \"indesign\", \"sketch\", \"figma\"\n",
    "        ],\n",
    "        \"Engineering\": [\n",
    "            \"engineering\", \"mechanical\", \"electrical\", \"civil\", \"industrial\", \"product development\",\n",
    "            \"cad\", \"technical specifications\", \"quality assurance\", \"testing\", \"manufacturing\",\n",
    "            \"design review\", \"product lifecycle\", \"structural analysis\", \"prototyping\", \"schematics\"\n",
    "        ],\n",
    "        \"Project Management\": [\n",
    "            \"project management\", \"program management\", \"agile\", \"scrum\", \"waterfall\", \"pmp\",\n",
    "            \"sprint planning\", \"stakeholder management\", \"risk management\", \"timeline\",\n",
    "            \"project planning\", \"resource allocation\", \"deliverables\", \"milestones\", \"kpis\"\n",
    "        ],\n",
    "        \"Human Resources\": [\n",
    "            \"recruitment\", \"talent acquisition\", \"onboarding\", \"benefits administration\",\n",
    "            \"employee relations\", \"performance management\", \"compensation\", \"training\",\n",
    "            \"development\", \"hr policies\", \"compliance\", \"diversity\", \"inclusion\", \"employee engagement\"\n",
    "        ],\n",
    "        \"Sales\": [\n",
    "            \"sales strategy\", \"business development\", \"account management\", \"client relationship\",\n",
    "            \"lead generation\", \"negotiation\", \"closing deals\", \"sales funnel\", \"crm\", \"salesforce\",\n",
    "            \"revenue growth\", \"pipeline management\", \"prospecting\", \"quota\", \"sales targets\"\n",
    "        ],\n",
    "        \"Customer Service\": [\n",
    "            \"customer support\", \"client satisfaction\", \"problem resolution\", \"customer experience\",\n",
    "            \"service level\", \"call center\", \"help desk\", \"ticketing system\", \"client communication\",\n",
    "            \"customer retention\", \"conflict resolution\", \"service recovery\", \"customer feedback\"\n",
    "        ],\n",
    "        \"Consulting\": [\n",
    "            \"consulting\", \"advisory\", \"client engagement\", \"solution development\", \"business analysis\",\n",
    "            \"process improvement\", \"strategy consulting\", \"change management\", \"requirements gathering\",\n",
    "            \"client presentations\", \"deliverables\", \"stakeholder management\", \"best practices\"\n",
    "        ],\n",
    "        \"Operations\": [\n",
    "            \"operations management\", \"process optimization\", \"supply chain\", \"logistics\",\n",
    "            \"inventory management\", \"quality control\", \"continuous improvement\", \"lean\",\n",
    "            \"six sigma\", \"resource planning\", \"operational efficiency\", \"workflow optimization\"\n",
    "        ],\n",
    "        \"Manufacturing\": [\n",
    "            \"manufacturing\", \"production\", \"quality control\", \"assembly\", \"fabrication\",\n",
    "            \"inventory\", \"supply chain\", \"lean manufacturing\", \"quality assurance\", \"six sigma\",\n",
    "            \"production planning\", \"operational efficiency\", \"machining\", \"plant operations\"\n",
    "        ],\n",
    "        \"Legal\": [\n",
    "            \"legal counsel\", \"contract review\", \"compliance\", \"regulatory\", \"litigation\",\n",
    "            \"legal research\", \"case management\", \"legal writing\", \"negotiation\", \"dispute resolution\",\n",
    "            \"legal analysis\", \"corporate law\", \"intellectual property\", \"legal documentation\"\n",
    "        ],\n",
    "        \"Content Writing\": [\n",
    "            \"content creation\", \"copywriting\", \"editing\", \"proofreading\", \"creative writing\",\n",
    "            \"blogging\", \"seo writing\", \"technical writing\", \"content strategy\", \"storytelling\",\n",
    "            \"content marketing\", \"article writing\", \"content management\", \"editorial\", \"publishing\"\n",
    "        ],\n",
    "        \"Administrative\": [\n",
    "            \"administrative support\", \"office management\", \"scheduling\", \"coordination\",\n",
    "            \"documentation\", \"record keeping\", \"filing\", \"data entry\", \"calendar management\",\n",
    "            \"meeting coordination\", \"office procedures\", \"executive support\", \"clerical\"\n",
    "        ],\n",
    "        \"Research\": [\n",
    "            \"research methodology\", \"data collection\", \"analysis\", \"literature review\",\n",
    "            \"experimental design\", \"research and development\", \"hypothesis testing\", \"qualitative research\",\n",
    "            \"quantitative research\", \"research proposal\", \"findings\", \"research paper\", \"publications\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Return keywords for the specified industry or a default list if not found\n",
    "    return keywords_by_industry.get(industry, [\"experience\", \"skills\", \"qualified\", \"professional\", \"proficient\", \"expertise\", \"knowledge\", \"background\", \"competent\"])\n",
    "\n",
    "def calculate_ats_score(text, industry):\n",
    "    \"\"\"Calculate ATS score based on multiple factors.\"\"\"\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Define components to evaluate\n",
    "    components = {\n",
    "        \"Format Quality\": {\"score\": 0, \"weight\": 15},\n",
    "        \"Keyword Relevance\": {\"score\": 0, \"weight\": 25},\n",
    "        \"Contact Information\": {\"score\": 0, \"weight\": 10},\n",
    "        \"Skills Coverage\": {\"score\": 0, \"weight\": 20},\n",
    "        \"Experience Clarity\": {\"score\": 0, \"weight\": 15},\n",
    "        \"Education Details\": {\"score\": 0, \"weight\": 10},\n",
    "        \"Summary/Objective\": {\"score\": 0, \"weight\": 5}\n",
    "    }\n",
    "    \n",
    "    # 1. Format Quality\n",
    "    # Check for common format issues\n",
    "    format_issues = []\n",
    "    if re.search(r'[^\\w\\s,.\\-():;@]', text):  # Check for special characters\n",
    "        format_issues.append(\"Special characters\")\n",
    "    if re.search(r'\\s{2,}', text):  # Check for multiple spaces\n",
    "        format_issues.append(\"Multiple spaces\")\n",
    "    \n",
    "    format_score = 100 - (len(format_issues) * 15)\n",
    "    components[\"Format Quality\"][\"score\"] = max(0, format_score)\n",
    "    \n",
    "    # 2. Keyword Relevance\n",
    "    industry_keywords = get_industry_keywords(industry)\n",
    "    keyword_matches = 0\n",
    "    \n",
    "    for keyword in industry_keywords:\n",
    "        if re.search(r'\\b' + re.escape(keyword) + r'\\b', text):\n",
    "            keyword_matches += 1\n",
    "    \n",
    "    keyword_score = min(100, (keyword_matches / len(industry_keywords) * 100))\n",
    "    components[\"Keyword Relevance\"][\"score\"] = keyword_score\n",
    "    \n",
    "    # 3. Contact Information\n",
    "    contact_info = extract_contact_info(text)\n",
    "    contact_score = min(100, (len(contact_info) / 3) * 100)  # 3 essential contact types\n",
    "    components[\"Contact Information\"][\"score\"] = contact_score\n",
    "    \n",
    "    # 4. Skills Coverage\n",
    "    all_skills = extract_skills_from_text(text)\n",
    "    tech_skills = [skill for skill, category in all_skills if category == 'technical']\n",
    "    soft_skills = [skill for skill, category in all_skills if category == 'soft']\n",
    "    \n",
    "    skill_score = 0\n",
    "    if tech_skills:\n",
    "        skill_score += 50  # 50% for technical skills presence\n",
    "    if soft_skills:\n",
    "        skill_score += 30  # 30% for soft skills presence\n",
    "    if len(tech_skills) >= 5 and len(soft_skills) >= 3:\n",
    "        skill_score += 20  # 20% for good balance and quantity\n",
    "    \n",
    "    components[\"Skills Coverage\"][\"score\"] = skill_score\n",
    "    \n",
    "    # 5. Experience Clarity\n",
    "    experience_years, experience_details = extract_experience_details(text)\n",
    "    \n",
    "    experience_score = 0\n",
    "    if experience_years:\n",
    "        experience_score += 50  # 50% for clear years\n",
    "    if experience_details:\n",
    "        experience_score += 50 * min(1, len(experience_details) / 2)  # Up to 50% based on details\n",
    "    \n",
    "    components[\"Experience Clarity\"][\"score\"] = experience_score\n",
    "    \n",
    "    # 6. Education Details\n",
    "    education_details = extract_education_dynamic(text)\n",
    "    \n",
    "    education_score = 0\n",
    "    if education_details:\n",
    "        if education_details.get(\"highest_degree\", \"Not Specified\") != \"Not Specified\":\n",
    "            education_score += 40  # 40% for degree specification\n",
    "        if education_details.get(\"institutions\", []):\n",
    "            education_score += 30  # 30% for institution(s)\n",
    "        if education_details.get(\"fields\", []):\n",
    "            education_score += 30  # 30% for field(s) of study\n",
    "    \n",
    "    components[\"Education Details\"][\"score\"] = education_score\n",
    "    \n",
    "    # 7. Summary/Objective\n",
    "    summary = extract_summary(text)\n",
    "    \n",
    "    summary_score = 0\n",
    "    if summary:\n",
    "        summary_score += 70  # 70% for having a summary\n",
    "        if len(summary.split()) >= 20:\n",
    "            summary_score += 30  # 30% for a substantial summary\n",
    "    \n",
    "    components[\"Summary/Objective\"][\"score\"] = summary_score\n",
    "    \n",
    "    # Calculate weighted score\n",
    "    final_score = 0\n",
    "    total_weight = 0\n",
    "    \n",
    "    for component, details in components.items():\n",
    "        final_score += details[\"score\"] * details[\"weight\"]\n",
    "        total_weight += details[\"weight\"]\n",
    "    \n",
    "    final_score = round(final_score / total_weight)\n",
    "    \n",
    "    return final_score, components\n",
    "\n",
    "def generate_ats_recommendations(text, ats_components, industry):\n",
    "    \"\"\"Generate recommendations for improving ATS score.\"\"\"\n",
    "    recommendations = {\n",
    "        \"Format & Structure\": [],\n",
    "        \"Keywords & Content\": [],\n",
    "        \"Missing Elements\": []\n",
    "    }\n",
    "    \n",
    "    # Analyze format issues\n",
    "    if ats_components[\"Format Quality\"][\"score\"] < 80:\n",
    "        recommendations[\"Format & Structure\"].append(\"Ensure your resume uses a clean, ATS-friendly format without tables, columns, or graphics.\")\n",
    "        recommendations[\"Format & Structure\"].append(\"Use standard section headers (e.g., 'Experience', 'Education', 'Skills').\")\n",
    "        recommendations[\"Format & Structure\"].append(\"Avoid special characters and symbols that may confuse ATS systems.\")\n",
    "    \n",
    "    # Analyze keyword issues\n",
    "    if ats_components[\"Keyword Relevance\"][\"score\"] < 70:\n",
    "        industry_keywords = get_industry_keywords(industry)\n",
    "        found_keywords = []\n",
    "        for keyword in industry_keywords:\n",
    "            if re.search(r'\\b' + re.escape(keyword) + r'\\b', text.lower()):\n",
    "                found_keywords.append(keyword)\n",
    "        \n",
    "        missing_keywords = [k for k in industry_keywords if k not in found_keywords]\n",
    "        if missing_keywords:\n",
    "            recommendations[\"Keywords & Content\"].append(f\"Add more industry-specific keywords relevant to {industry}.\")\n",
    "            recommendations[\"Keywords & Content\"].append(\"Tailor your resume for each job application by including keywords from the job description.\")\n",
    "    \n",
    "    # Skills recommendations\n",
    "    all_skills = extract_skills_from_text(text)\n",
    "    tech_skills = [skill for skill, category in all_skills if category == 'technical']\n",
    "    soft_skills = [skill for skill, category in all_skills if category == 'soft']\n",
    "    \n",
    "    if len(tech_skills) < 5:\n",
    "        recommendations[\"Keywords & Content\"].append(\"Include more technical skills relevant to your target role.\")\n",
    "    if len(soft_skills) < 3:\n",
    "        recommendations[\"Keywords & Content\"].append(\"Add more soft skills to demonstrate your well-rounded capabilities.\")\n",
    "    \n",
    "    # Contact information issues\n",
    "    contact_info = extract_contact_info(text)\n",
    "    essential_contacts = ['Email', 'Phone', 'LinkedIn']\n",
    "    missing = [item for item in essential_contacts if item not in contact_info]\n",
    "    if missing:\n",
    "        recommendations[\"Missing Elements\"].append(f\"Add missing contact information: {', '.join(missing)}.\")\n",
    "    \n",
    "    # Experience issues\n",
    "    if ats_components[\"Experience Clarity\"][\"score\"] < 70:\n",
    "        recommendations[\"Format & Structure\"].append(\"Use clear date formats for your work experience (MM/YYYY - MM/YYYY).\")\n",
    "        recommendations[\"Keywords & Content\"].append(\"Quantify your achievements with metrics and results where possible.\")\n",
    "    \n",
    "    # Education issues\n",
    "    if ats_components[\"Education Details\"][\"score\"] < 70:\n",
    "        recommendations[\"Format & Structure\"].append(\"Clearly structure your education section with degree, institution, and graduation year.\")\n",
    "    \n",
    "    # Summary issues\n",
    "    if ats_components[\"Summary/Objective\"][\"score\"] < 50:\n",
    "        recommendations[\"Missing Elements\"].append(\"Add a concise professional summary that highlights your key qualifications.\")\n",
    "    \n",
    "    # General recommendations\n",
    "    if not recommendations[\"Keywords & Content\"]:\n",
    "        recommendations[\"Keywords & Content\"].append(\"Use action verbs to describe your achievements and responsibilities.\")\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "def analyze_resume_format(text):\n",
    "    \"\"\"Analyze resume formatting for ATS compatibility.\"\"\"\n",
    "    format_issues = []\n",
    "    \n",
    "    # Check for tables/columns indicators\n",
    "    if re.search(r'\\|\\s*\\|', text) or re.search(r'\\+---+\\+', text):\n",
    "        format_issues.append(\"Possible table structure detected - tables can confuse ATS systems\")\n",
    "    \n",
    "    # Check for fancy characters\n",
    "    if re.search(r'[‚ò∫‚òª‚ô•‚ô¶‚ô£‚ô†‚Ä¢‚óò‚óã‚óô‚ôÇ‚ôÄ‚ô™‚ô´‚òº‚ñ∫‚óÑ‚Üï‚Äº¬∂¬ß‚ñ¨‚Ü®‚Üë‚Üì‚Üí‚Üê‚àü‚Üî‚ñ≤‚ñº]', text):\n",
    "        format_issues.append(\"Special characters detected - replace with standard text characters\")\n",
    "    \n",
    "    # Check for inconsistent spacing\n",
    "    if re.search(r'\\n\\s*\\n\\s*\\n', text):\n",
    "        format_issues.append(\"Inconsistent spacing detected - maintain consistent formatting\")\n",
    "    \n",
    "    # Check for potential header/footer content\n",
    "    header_footer_patterns = [\n",
    "        r'page \\d+ of \\d+',\n",
    "        r'confidential',\n",
    "        r'resume of',\n",
    "        r'curriculum vitae of'\n",
    "    ]\n",
    "    \n",
    "    for pattern in header_footer_patterns:\n",
    "        if re.search(pattern, text, re.IGNORECASE):\n",
    "            format_issues.append(\"Headers/footers detected - remove them for better ATS compatibility\")\n",
    "            break\n",
    "    \n",
    "    # Check for image indicators\n",
    "    image_indicators = [\n",
    "        r'\\[image\\]',\n",
    "        r'\\[photo\\]',\n",
    "        r'\\[logo\\]',\n",
    "        r'<img',\n",
    "        r'data:image'\n",
    "    ]\n",
    "    \n",
    "    for indicator in image_indicators:\n",
    "        if re.search(indicator, text, re.IGNORECASE):\n",
    "            format_issues.append(\"Image detected - remove images for better ATS compatibility\")\n",
    "            break\n",
    "    \n",
    "    # Check file format implications\n",
    "    if re.search(r'\\.docx|\\.pdf|\\.doc|\\.rtf', text, re.IGNORECASE):\n",
    "        format_issues.append(\"Ensure you're using a standard .docx or .pdf format for ATS compatibility\")\n",
    "    \n",
    "    return format_issues\n",
    "\n",
    "def analyze_keyword_positions(text, keywords):\n",
    "    \"\"\"Analyze positioning of keywords throughout the resume.\"\"\"\n",
    "    paragraphs = re.split(r'\\n\\s*\\n', text)\n",
    "    \n",
    "    # Check if keywords appear in the first paragraph (summary/objective)\n",
    "    first_para_keywords = 0\n",
    "    if paragraphs:\n",
    "        for keyword in keywords:\n",
    "            if re.search(r'\\b' + re.escape(keyword) + r'\\b', paragraphs[0].lower()):\n",
    "                first_para_keywords += 1\n",
    "    \n",
    "    first_para_score = min(100, (first_para_keywords / max(1, len(keywords))) * 100)\n",
    "    \n",
    "    # Check for keyword distribution throughout the document\n",
    "    keyword_positions = []\n",
    "    for keyword in keywords:\n",
    "        for match in re.finditer(r'\\b' + re.escape(keyword) + r'\\b', text.lower()):\n",
    "            position = match.start() / len(text)  # Normalized position (0-1)\n",
    "            keyword_positions.append(position)\n",
    "    \n",
    "    # Calculate distribution score\n",
    "    distribution_score = 0\n",
    "    if keyword_positions:\n",
    "        # Divide document into sections and check coverage\n",
    "        sections = 4\n",
    "        section_counts = [0] * sections\n",
    "        \n",
    "        for pos in keyword_positions:\n",
    "            section_idx = min(int(pos * sections), sections - 1)\n",
    "            section_counts[section_idx] += 1\n",
    "        \n",
    "        # Calculate how many sections have at least one keyword\n",
    "        covered_sections = sum(1 for count in section_counts if count > 0)\n",
    "        distribution_score = (covered_sections / sections) * 100\n",
    "    \n",
    "    # Final score is average of first paragraph and distribution scores\n",
    "    position_score = (first_para_score + distribution_score) / 2\n",
    "    \n",
    "    # Generate suggestion\n",
    "    if first_para_score < 50:\n",
    "        suggestion = \"Include more relevant keywords in your summary or objective section.\"\n",
    "    elif distribution_score < 50:\n",
    "        suggestion = \"Distribute your keywords more evenly throughout your resume.\"\n",
    "    else:\n",
    "        suggestion = \"Your keyword positioning looks good! Keywords are well distributed throughout your resume.\"\n",
    "    \n",
    "    return {\n",
    "        \"score\": round(position_score),\n",
    "        \"first_paragraph_score\": round(first_para_score),\n",
    "        \"distribution_score\": round(distribution_score),\n",
    "        \"suggestion\": suggestion\n",
    "    }\n",
    "\n",
    "# Define a basic industry classifier using a simple model\n",
    "def get_industry_model():\n",
    "    \"\"\"Return a simple industry classification model.\"\"\"\n",
    "    # Return a simple dictionary-based approach\n",
    "    # In a real application, this might be a more sophisticated ML model\n",
    "    return {\n",
    "        \"industry_keywords\": {\n",
    "            \"Software Development\": [\"software\", \"developer\", \"programming\", \"java\", \"python\", \"javascript\"],\n",
    "            \"Data Science\": [\"data science\", \"machine learning\", \"ai\", \"statistics\", \"analytics\"],\n",
    "            \"Finance\": [\"finance\", \"accounting\", \"financial\", \"investment\", \"banking\"],\n",
    "            \"Marketing\": [\"marketing\", \"digital\", \"social media\", \"brand\", \"content\"],\n",
    "            \"Healthcare\": [\"healthcare\", \"medical\", \"clinical\", \"patient\", \"health\"],\n",
    "            \"Education\": [\"education\", \"teacher\", \"academic\", \"student\", \"teaching\"],\n",
    "            \"Design\": [\"design\", \"ui\", \"ux\", \"graphic\", \"creative\"],\n",
    "            \"Engineering\": [\"engineering\", \"mechanical\", \"electrical\", \"civil\", \"structural\"],\n",
    "            \"Project Management\": [\"project manager\", \"agile\", \"scrum\", \"pmp\", \"delivery\"],\n",
    "            \"Human Resources\": [\"hr\", \"human resources\", \"recruitment\", \"talent\", \"hiring\"]\n",
    "        },\n",
    "        \"predict\": lambda text, keywords: {\n",
    "            name: sum(1 for kw in kws if re.search(r'\\b' + re.escape(kw) + r'\\b', text.lower()))\n",
    "            for name, kws in keywords.items()\n",
    "        }\n",
    "    }\n",
    "\n",
    "def classify_industry(text):\n",
    "    \"\"\"Classify the industry of a resume using the simple model.\"\"\"\n",
    "    model = get_industry_model()\n",
    "    scores = model[\"predict\"](text, model[\"industry_keywords\"])\n",
    "    \n",
    "    # Get the industry with the highest score\n",
    "    if scores:\n",
    "        max_industry = max(scores.items(), key=lambda x: x[1])\n",
    "        if max_industry[1] > 0:\n",
    "            return max_industry[0]\n",
    "    \n",
    "    return \"General\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
